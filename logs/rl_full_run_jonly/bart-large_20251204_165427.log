Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Using device: mps
Loading policy initialization from TRAIN/bart-large/final_model
Epoch 1/10
  Step 01: reward=0.1417 loss=1.5500 kl=-0.8833
  Step 02: reward=0.1238 loss=2.6067 kl=0.0358
  Step 03: reward=0.1184 loss=0.7027 kl=0.4858
  Step 04: reward=0.1245 loss=1.0313 kl=1.3736
  Step 05: reward=0.1190 loss=0.8797 kl=-0.6305
  Step 06: reward=0.1170 loss=1.3252 kl=-0.5380
  Step 07: reward=0.1229 loss=0.5940 kl=0.0551
  Step 08: reward=0.1319 loss=2.5859 kl=-1.0211
  Step 09: reward=0.1395 loss=1.5983 kl=-0.8706
  Step 10: reward=0.1314 loss=1.2676 kl=-0.3176
  Step 11: reward=0.1215 loss=1.7247 kl=-0.1256
  Step 12: reward=0.1754 loss=0.8529 kl=-0.6153
  Step 13: reward=0.1188 loss=2.1108 kl=-0.8584
  Step 14: reward=0.1278 loss=6.7708 kl=-0.8005
  Step 15: reward=0.1218 loss=0.4803 kl=0.1067
  Step 16: reward=0.1303 loss=2.2605 kl=-0.8708
  Step 17: reward=0.1268 loss=0.7004 kl=0.4865
  Step 18: reward=0.1205 loss=2.4964 kl=-0.3735
  Step 19: reward=0.1164 loss=1.2896 kl=0.9098
  Step 20: reward=0.1249 loss=0.7190 kl=0.0168
  Step 21: reward=0.1270 loss=0.7697 kl=-0.6739
  Step 22: reward=0.1299 loss=0.7053 kl=0.1862
  Step 23: reward=0.1291 loss=0.4449 kl=0.1631
  Step 24: reward=0.1218 loss=2.1135 kl=3.3042
  Step 25: reward=0.1246 loss=3.1188 kl=-0.9822
  Step 26: reward=0.1307 loss=0.3499 kl=-0.1614
  Step 27: reward=0.1555 loss=0.3967 kl=-0.2505
  Step 28: reward=0.1237 loss=1.5507 kl=-0.6761
  Step 29: reward=0.1507 loss=0.7467 kl=-0.1679
  Step 30: reward=0.1277 loss=0.5291 kl=0.1807
  Step 31: reward=0.1304 loss=0.6196 kl=0.2659
  Step 32: reward=0.1753 loss=1.6981 kl=2.0470
  Step 33: reward=0.1144 loss=3.7767 kl=-0.8299
  Step 34: reward=0.1199 loss=0.8172 kl=-0.1131
  Step 35: reward=0.1229 loss=1.9049 kl=0.1766
  Step 36: reward=0.1257 loss=1.7617 kl=-0.0058
  Step 37: reward=0.1204 loss=1.3553 kl=-0.5781
  Step 38: reward=0.1288 loss=0.6590 kl=-0.1747
  Step 39: reward=0.1233 loss=5.2202 kl=-0.2625
  Step 40: reward=0.1315 loss=1.3309 kl=0.3847
  Step 41: reward=0.1225 loss=50.0443 kl=-0.1599
  Step 42: reward=0.1220 loss=3.0442 kl=3.8940
  Step 43: reward=0.1241 loss=8.5070 kl=-0.8093
  Step 44: reward=0.1525 loss=1.3303 kl=0.5244
  Step 45: reward=0.1167 loss=0.5140 kl=0.1361
  Step 46: reward=0.1260 loss=0.5561 kl=0.1061
  Step 47: reward=0.1138 loss=6.0050 kl=-0.1429
  Step 48: reward=0.1268 loss=18.5484 kl=0.3279
  Step 49: reward=0.1234 loss=1.4919 kl=0.8222
  Step 50: reward=0.1248 loss=0.5367 kl=0.1844
  Eval reward=0.6075 toxicity=0.0804
Epoch 2/10
  Step 01: reward=0.1255 loss=0.5491 kl=0.3626
  Step 02: reward=0.1260 loss=1.7565 kl=1.7244
  Step 03: reward=0.1249 loss=2.8469 kl=2.9921
  Step 04: reward=0.1242 loss=2.4097 kl=1.4566
  Step 05: reward=0.1564 loss=1.0175 kl=-0.4483
  Step 06: reward=0.1189 loss=1.1224 kl=0.8045
  Step 07: reward=0.1259 loss=1.9779 kl=1.3070
  Step 08: reward=0.1204 loss=2.5005 kl=0.6941
  Step 09: reward=0.1275 loss=2.4555 kl=1.3423
  Step 10: reward=0.1314 loss=1.1308 kl=-0.3017
  Step 11: reward=0.1354 loss=1.3717 kl=-0.2825
  Step 12: reward=0.1260 loss=2.5085 kl=1.6123
  Step 13: reward=0.1245 loss=0.5587 kl=0.2339
  Step 14: reward=0.1231 loss=3.3452 kl=1.1207
  Step 15: reward=0.1282 loss=1.0155 kl=0.2560
  Step 16: reward=0.1416 loss=1.0538 kl=0.7072
  Step 17: reward=0.1486 loss=2.1187 kl=-0.3191
  Step 18: reward=0.1300 loss=2.0327 kl=1.5286
  Step 19: reward=0.1227 loss=1.3080 kl=-0.3225
  Step 20: reward=0.1675 loss=7.4940 kl=-0.0035
  Step 21: reward=0.1239 loss=6.7328 kl=0.1285
  Step 22: reward=0.1299 loss=0.8442 kl=0.3309
  Step 23: reward=0.1193 loss=2.6179 kl=1.2526
  Step 24: reward=0.1179 loss=76144.0391 kl=-0.7423
  Step 25: reward=0.1241 loss=2.9199 kl=2.4821
  Step 26: reward=0.1214 loss=3.6759 kl=0.7072
  Step 27: reward=0.1299 loss=1.1275 kl=0.7378
  Step 28: reward=0.1297 loss=1.5780 kl=0.9366
  Step 29: reward=0.1175 loss=2.6106 kl=2.0958
  Step 30: reward=0.1244 loss=0.2848 kl=-0.0362
  Step 31: reward=0.1194 loss=115.5691 kl=-0.3394
  Step 32: reward=0.1302 loss=2.0520 kl=1.0435
  Step 33: reward=0.1187 loss=1.0127 kl=0.3876
  Step 34: reward=0.1278 loss=1.1140 kl=0.5658
  Step 35: reward=0.1298 loss=1.3529 kl=-0.0444
  Step 36: reward=0.1295 loss=4.4964 kl=0.8362
  Step 37: reward=0.1291 loss=1.4684 kl=0.8796
  Step 38: reward=0.1184 loss=12.3227 kl=0.7707
  Step 39: reward=0.1166 loss=0.9933 kl=0.1133
  Step 40: reward=0.1731 loss=0.8802 kl=0.5644
  Step 41: reward=0.1299 loss=0.7805 kl=0.3668
  Step 42: reward=0.1282 loss=1.6925 kl=0.4847
  Step 43: reward=0.1408 loss=1.6198 kl=0.3180
  Step 44: reward=0.1259 loss=1.9433 kl=1.3435
  Step 45: reward=0.1167 loss=0.5148 kl=-0.1162
  Step 46: reward=0.1237 loss=3.1564 kl=2.3253
  Step 47: reward=0.1773 loss=5.0094 kl=4.4057
  Step 48: reward=0.1239 loss=4.6709 kl=0.5761
  Step 49: reward=0.1283 loss=2.2902 kl=1.7382
  Step 50: reward=0.1722 loss=1.7462 kl=1.2894
  Eval reward=0.6134 toxicity=0.0826
Epoch 3/10
  Step 01: reward=0.1239 loss=2.8816 kl=2.4783
  Step 02: reward=0.1178 loss=1.2301 kl=0.5683
  Step 03: reward=0.1281 loss=0.8279 kl=0.3062
  Step 04: reward=0.1226 loss=1.8269 kl=1.4336
  Step 05: reward=0.1605 loss=5.9596 kl=5.2698
  Step 06: reward=0.1465 loss=1.1560 kl=0.2850
  Step 07: reward=0.1296 loss=1.2395 kl=0.7519
  Step 08: reward=0.1235 loss=0.7953 kl=0.1672
  Step 09: reward=0.1297 loss=0.6447 kl=-0.2779
  Step 10: reward=0.1253 loss=5.1800 kl=1.9756
  Step 11: reward=0.1264 loss=2.8690 kl=2.2294
  Step 12: reward=0.1202 loss=0.8189 kl=0.3843
  Step 13: reward=0.1269 loss=2.7518 kl=2.1426
  Step 14: reward=0.1357 loss=0.5276 kl=-0.0053
  Step 15: reward=0.1256 loss=2.4802 kl=1.8166
  Step 16: reward=0.1275 loss=1.6779 kl=0.8219
  Step 17: reward=0.1182 loss=4.6089 kl=-0.6479
  Step 18: reward=0.1237 loss=2.3299 kl=1.8115
  Step 19: reward=0.1280 loss=1.1237 kl=0.1186
  Step 20: reward=0.1303 loss=0.9940 kl=0.0530
  Step 21: reward=0.1252 loss=1.7041 kl=1.5359
  Step 22: reward=0.1227 loss=4.6612 kl=0.8467
  Step 23: reward=0.1308 loss=1.1059 kl=0.1256
  Step 24: reward=0.1208 loss=2.1182 kl=1.7902
  Step 25: reward=0.1266 loss=21.2412 kl=-0.2740
  Step 26: reward=0.1547 loss=2.2881 kl=0.1480
  Step 27: reward=0.1126 loss=0.9205 kl=-0.0832
  Step 28: reward=0.1240 loss=0.8707 kl=0.4715
  Step 29: reward=0.1233 loss=86.0156 kl=0.2622
  Step 30: reward=0.1277 loss=2.7744 kl=0.9346
  Step 31: reward=0.1170 loss=0.9096 kl=0.2139
  Step 32: reward=0.1230 loss=0.8910 kl=0.0882
  Step 33: reward=0.1244 loss=2.5522 kl=2.1894
  Step 34: reward=0.1246 loss=7.5235 kl=7.0587
  Step 35: reward=0.1255 loss=1.4221 kl=0.5882
  Step 36: reward=0.1301 loss=1.3839 kl=0.4436
  Step 37: reward=0.1237 loss=1.3963 kl=0.5372
  Step 38: reward=0.1551 loss=2.4852 kl=1.7087
  Step 39: reward=0.1353 loss=8.0217 kl=0.4599
  Step 40: reward=0.1238 loss=1.4521 kl=0.7485
  Step 41: reward=0.1320 loss=2.1649 kl=1.7232
  Step 42: reward=0.1260 loss=1.1541 kl=0.7213
  Step 43: reward=0.1271 loss=2.5890 kl=2.0470
  Step 44: reward=0.1151 loss=3.6871 kl=1.6834
  Step 45: reward=0.1263 loss=1.6462 kl=1.2630
  Step 46: reward=0.1168 loss=3.8141 kl=3.1050
  Step 47: reward=0.1233 loss=1.6331 kl=0.6742
  Step 48: reward=0.1180 loss=1.8874 kl=1.4587
  Step 49: reward=0.1319 loss=68.0070 kl=2.0432
  Step 50: reward=0.1240 loss=3.2263 kl=2.6182
  Eval reward=0.6174 toxicity=0.0870
Epoch 4/10
  Step 01: reward=0.1284 loss=3.3710 kl=2.8034
  Step 02: reward=0.1237 loss=3.2430 kl=2.6177
  Step 03: reward=0.1301 loss=2.1660 kl=1.3137
  Step 04: reward=0.1189 loss=2.4568 kl=1.4427
  Step 05: reward=0.1348 loss=2.0451 kl=1.5370
  Step 06: reward=0.1173 loss=2.3452 kl=1.9724
  Step 07: reward=0.1215 loss=2.4763 kl=1.7364
  Step 08: reward=0.1253 loss=2.0731 kl=1.4757
  Step 09: reward=0.1298 loss=2.1859 kl=1.3732
  Step 10: reward=0.1181 loss=7.3591 kl=1.2346
  Step 11: reward=0.1212 loss=3.1342 kl=2.5944
  Step 12: reward=0.1390 loss=2.9760 kl=2.3624
  Step 13: reward=0.1181 loss=1.2953 kl=0.4132
  Step 14: reward=0.1226 loss=1.9680 kl=1.1120
  Step 15: reward=0.1258 loss=7.3611 kl=1.1267
  Step 16: reward=0.1321 loss=1.8233 kl=1.4602
  Step 17: reward=0.1222 loss=2.8145 kl=2.3935
  Step 18: reward=0.1194 loss=1.5961 kl=0.9356
  Step 19: reward=0.1217 loss=3.0372 kl=2.0663
  Step 20: reward=0.1155 loss=1.8453 kl=1.3278
  Step 21: reward=0.1605 loss=3.3919 kl=1.5568
  Step 22: reward=0.1220 loss=2.2074 kl=0.8176
  Step 23: reward=0.1305 loss=1.9556 kl=1.5385
  Step 24: reward=0.1159 loss=1.2954 kl=1.0316
  Step 25: reward=0.1446 loss=5.2934 kl=2.0174
  Step 26: reward=0.1288 loss=1.8596 kl=0.5238
  Step 27: reward=0.1258 loss=1.9150 kl=0.7094
  Step 28: reward=0.1281 loss=1.1268 kl=0.3135
  Step 29: reward=0.1149 loss=2.1987 kl=1.1010
  Step 30: reward=0.1285 loss=0.7434 kl=-0.2024
  Step 31: reward=0.1263 loss=1.1131 kl=0.5104
  Step 32: reward=0.1272 loss=0.9868 kl=0.1361
  Step 33: reward=0.1271 loss=2.5217 kl=1.9878
  Step 34: reward=0.1292 loss=2.2684 kl=-0.4715
  Step 35: reward=0.1332 loss=0.7672 kl=-0.0980
  Step 36: reward=0.1241 loss=1.6510 kl=1.0972
  Step 37: reward=0.1218 loss=2.9612 kl=-0.3841
  Step 38: reward=0.1272 loss=1.3632 kl=0.2591
  Step 39: reward=0.1278 loss=2.1344 kl=0.7966
  Step 40: reward=0.1214 loss=35.8065 kl=0.1951
  Step 41: reward=0.1289 loss=1.5849 kl=1.1516
  Step 42: reward=0.1288 loss=0.6386 kl=0.2767
  Step 43: reward=0.1255 loss=5.3100 kl=1.3532
  Step 44: reward=0.1276 loss=0.8406 kl=0.2177
  Step 45: reward=0.1283 loss=9.2755 kl=1.1112
  Step 46: reward=0.1242 loss=1.7276 kl=0.6271
  Step 47: reward=0.1274 loss=1.7728 kl=1.2726
  Step 48: reward=0.1356 loss=0.9329 kl=0.2280
  Step 49: reward=0.1230 loss=3.2544 kl=1.1991
  Step 50: reward=0.1270 loss=1.0675 kl=-0.0522
  Eval reward=0.6158 toxicity=0.0895
Epoch 5/10
  Step 01: reward=0.1225 loss=2.0360 kl=0.4395
  Step 02: reward=0.1251 loss=5.1905 kl=-0.1717
  Step 03: reward=0.1171 loss=1.8127 kl=1.4428
  Step 04: reward=0.1284 loss=1.0712 kl=0.4901
  Step 05: reward=0.1261 loss=1.6359 kl=0.3153
  Step 06: reward=0.1291 loss=1.3497 kl=0.0304
  Step 07: reward=0.1278 loss=0.6100 kl=-0.0502
  Step 08: reward=0.1206 loss=1.8316 kl=1.5053
  Step 09: reward=0.1259 loss=2.8702 kl=-0.4776
  Step 10: reward=0.1313 loss=2.4754 kl=0.3723
  Step 11: reward=0.1314 loss=1.0458 kl=0.3192
  Step 12: reward=0.1266 loss=1.6133 kl=0.9819
  Step 13: reward=0.1311 loss=1.5461 kl=0.2181
  Step 14: reward=0.1161 loss=2.3405 kl=0.9847
  Step 15: reward=0.1218 loss=1.9219 kl=1.0161
  Step 16: reward=0.1246 loss=2.0292 kl=1.0576
  Step 17: reward=0.1258 loss=2.0224 kl=1.2021
  Step 18: reward=0.1231 loss=3.2862 kl=-0.1314
  Step 19: reward=0.1226 loss=1.1567 kl=0.1762
  Step 20: reward=0.1253 loss=1.9430 kl=0.7896
  Step 21: reward=0.1215 loss=1.3894 kl=0.7336
  Step 22: reward=0.1279 loss=1.8550 kl=1.0960
  Step 23: reward=0.1283 loss=0.7309 kl=0.1533
  Step 24: reward=0.1235 loss=0.6885 kl=0.3068
  Step 25: reward=0.1161 loss=2.4392 kl=0.7055
  Step 26: reward=0.1237 loss=2.2558 kl=0.6489
  Step 27: reward=0.1265 loss=1.1545 kl=-0.0553
  Step 28: reward=0.1221 loss=1.8671 kl=1.0067
  Step 29: reward=0.1275 loss=0.9934 kl=0.1658
  Step 30: reward=0.1390 loss=2.8965 kl=1.4504
  Step 31: reward=0.1167 loss=2.2849 kl=1.2161
  Step 32: reward=0.1226 loss=1.6893 kl=0.9104
  Step 33: reward=0.1236 loss=2.2726 kl=0.6420
  Step 34: reward=0.1243 loss=1.3657 kl=0.8974
  Step 35: reward=0.1424 loss=5.0065 kl=0.3986
  Step 36: reward=0.1210 loss=9.4893 kl=0.6685
  Step 37: reward=0.1272 loss=1.0081 kl=0.6760
  Step 38: reward=0.1168 loss=1.6536 kl=1.1806
  Step 39: reward=0.1230 loss=4.1730 kl=0.2222
  Step 40: reward=0.1231 loss=1.4471 kl=0.7552
  Step 41: reward=0.1296 loss=1.6731 kl=1.2119
  Step 42: reward=0.1286 loss=1.4989 kl=0.9016
  Step 43: reward=0.1295 loss=1.0945 kl=-0.4128
  Step 44: reward=0.1229 loss=2.0340 kl=0.4665
  Step 45: reward=0.1239 loss=2.0336 kl=1.3211
  Step 46: reward=0.1219 loss=7837.0562 kl=0.8196
  Step 47: reward=0.1327 loss=1.2741 kl=0.6342
  Step 48: reward=0.1243 loss=1.8492 kl=0.4291
  Step 49: reward=0.1222 loss=1.6196 kl=0.8805
  Step 50: reward=0.1314 loss=1.9192 kl=0.8876
  Eval reward=0.6103 toxicity=0.0885
Epoch 6/10
  Step 01: reward=0.1249 loss=1.4553 kl=0.2501
  Step 02: reward=0.1255 loss=4.0047 kl=-0.0047
  Step 03: reward=0.1328 loss=0.8759 kl=0.4695
  Step 04: reward=0.1280 loss=1.4694 kl=0.4978
  Step 05: reward=0.1249 loss=1.8585 kl=-0.1491
  Step 06: reward=0.1257 loss=1.1565 kl=0.5764
  Step 07: reward=0.1310 loss=2.5978 kl=1.2222
  Step 08: reward=0.1256 loss=7.4341 kl=0.1007
  Step 09: reward=0.1287 loss=1.0070 kl=0.6607
  Step 10: reward=0.1264 loss=102.6438 kl=-0.0951
  Step 11: reward=0.1423 loss=1.9271 kl=1.4514
  Step 12: reward=0.1272 loss=1.5401 kl=0.6128
  Step 13: reward=0.1146 loss=1.9581 kl=1.1109
  Step 14: reward=0.1305 loss=2.5554 kl=1.1435
  Step 15: reward=0.1164 loss=19.3023 kl=0.7390
  Step 16: reward=0.1272 loss=0.7065 kl=0.2190
  Step 17: reward=0.1259 loss=65.9788 kl=-0.7134
  Step 18: reward=0.1196 loss=3.6623 kl=0.7187
  Step 19: reward=0.1183 loss=2.7661 kl=0.5258
  Step 20: reward=0.1255 loss=2.2125 kl=-0.3528
  Step 21: reward=0.1234 loss=1.8570 kl=0.8458
  Step 22: reward=0.1236 loss=0.7177 kl=0.2881
  Step 23: reward=0.1199 loss=1.6827 kl=1.0517
  Step 24: reward=0.1187 loss=1.1862 kl=0.0796
  Step 25: reward=0.1154 loss=1.6355 kl=0.6122
  Step 26: reward=0.1258 loss=0.4321 kl=-0.0443
  Step 27: reward=0.1278 loss=0.9904 kl=0.6445
  Step 28: reward=0.1255 loss=0.9346 kl=-0.1549
  Step 29: reward=0.1254 loss=1.5832 kl=-0.4402
  Step 30: reward=0.1353 loss=0.7705 kl=0.1742
  Step 31: reward=0.1285 loss=0.8054 kl=0.2377
  Step 32: reward=0.1302 loss=2.0583 kl=1.4827
  Step 33: reward=0.1300 loss=1.8386 kl=1.3790
  Step 34: reward=0.1305 loss=0.8669 kl=-0.1323
  Step 35: reward=0.1259 loss=4.7268 kl=-0.3139
  Step 36: reward=0.1250 loss=0.9870 kl=0.6307
  Step 37: reward=0.1302 loss=46.2604 kl=0.8285
  Step 38: reward=0.1244 loss=1.8884 kl=0.1546
  Step 39: reward=0.1241 loss=1.6838 kl=1.1653
  Step 40: reward=0.1292 loss=1.3166 kl=0.7154
  Step 41: reward=0.1247 loss=53.8208 kl=0.2404
  Step 42: reward=0.1215 loss=8.7723 kl=7.0804
  Step 43: reward=0.1296 loss=2.1351 kl=1.1539
  Step 44: reward=0.1361 loss=2.3944 kl=0.3029
  Step 45: reward=0.1243 loss=9.6591 kl=1.0963
  Step 46: reward=0.1229 loss=1.6682 kl=1.0712
  Step 47: reward=0.1268 loss=2.9944 kl=1.5503
  Step 48: reward=0.1262 loss=1.9205 kl=0.2752
  Step 49: reward=0.1442 loss=375784.9375 kl=-1.5735
  Step 50: reward=0.1249 loss=0.7142 kl=0.3695
  Eval reward=0.5992 toxicity=0.0841
Epoch 7/10
  Step 01: reward=0.1335 loss=1.6281 kl=0.9585
  Step 02: reward=0.1301 loss=4.3883 kl=1.8552
  Step 03: reward=0.1282 loss=2.5448 kl=0.9513
  Step 04: reward=0.1307 loss=1.3306 kl=-0.2454
  Step 05: reward=0.1275 loss=2.8859 kl=2.3563
  Step 06: reward=0.1298 loss=2.8059 kl=-0.4659
  Step 07: reward=0.1177 loss=0.7966 kl=0.1329
  Step 08: reward=0.1195 loss=61.4938 kl=0.0559
  Step 09: reward=0.1232 loss=1.5120 kl=0.0710
  Step 10: reward=0.1269 loss=2.1766 kl=1.5788
  Step 11: reward=0.1162 loss=0.7635 kl=0.0625
  Step 12: reward=0.1660 loss=1.6255 kl=-0.3212
  Step 13: reward=0.1170 loss=1.2310 kl=1.0436
  Step 14: reward=0.1258 loss=0.7491 kl=0.3688
  Step 15: reward=0.1323 loss=0.4923 kl=-0.1759
  Step 16: reward=0.1180 loss=47.9016 kl=0.1431
  Step 17: reward=0.1167 loss=18.0778 kl=-0.3936
  Step 18: reward=0.1225 loss=151.3486 kl=0.3036
  Step 19: reward=0.1193 loss=1.3116 kl=0.3167
  Step 20: reward=0.1281 loss=0.7183 kl=0.3184
  Step 21: reward=0.1205 loss=1.1896 kl=0.8809
  Step 22: reward=0.1447 loss=1.2393 kl=0.9486
  Step 23: reward=0.1299 loss=1.7424 kl=1.1674
  Step 24: reward=0.1220 loss=0.8543 kl=-0.1225
  Step 25: reward=0.1171 loss=5.3962 kl=-0.1172
  Step 26: reward=0.1219 loss=1.5614 kl=0.7183
  Step 27: reward=0.1229 loss=1.4148 kl=-0.0789
  Step 28: reward=0.1256 loss=0.4958 kl=0.1535
  Step 29: reward=0.1310 loss=1.8250 kl=0.9105
  Step 30: reward=0.1179 loss=1.5998 kl=-0.3962
  Step 31: reward=0.1252 loss=1.4784 kl=0.8999
  Step 32: reward=0.1318 loss=1.6940 kl=1.2819
  Step 33: reward=0.1287 loss=1.5392 kl=0.9459
  Step 34: reward=0.1252 loss=1.9504 kl=1.4082
  Step 35: reward=0.1322 loss=13.6179 kl=0.7364
  Step 36: reward=0.1218 loss=9.9400 kl=2.2406
  Step 37: reward=0.1443 loss=0.9584 kl=0.7362
  Step 38: reward=0.1252 loss=6.4505 kl=0.4431
  Step 39: reward=0.1242 loss=1.7157 kl=0.5272
  Step 40: reward=0.1281 loss=0.9581 kl=-0.4085
  Step 41: reward=0.1272 loss=1.5954 kl=-0.6580
  Step 42: reward=0.1235 loss=1.2096 kl=-0.0134
  Step 43: reward=0.1311 loss=1.2337 kl=0.4700
  Step 44: reward=0.1289 loss=2.1462 kl=-0.5703
  Step 45: reward=0.1407 loss=1.0417 kl=0.3142
  Step 46: reward=0.1335 loss=0.4356 kl=-0.0486
  Step 47: reward=0.1262 loss=1.7152 kl=0.2191
  Step 48: reward=0.1468 loss=0.9120 kl=-0.3003
  Step 49: reward=0.1244 loss=0.8532 kl=0.0051
  Step 50: reward=0.1203 loss=36.2732 kl=0.3219
  Eval reward=0.6094 toxicity=0.0743
Epoch 8/10
  Step 01: reward=0.1179 loss=11.0420 kl=0.0187
  Step 02: reward=0.1282 loss=1.3359 kl=0.8434
  Step 03: reward=0.1270 loss=0.6959 kl=0.3059
  Step 04: reward=0.1246 loss=197.8399 kl=-0.0762
  Step 05: reward=0.1262 loss=0.9480 kl=0.8517
  Step 06: reward=0.1293 loss=8.5933 kl=-0.5024
  Step 07: reward=0.1301 loss=1.5502 kl=-0.2602
  Step 08: reward=0.1293 loss=1.5485 kl=0.6175
  Step 09: reward=0.1265 loss=1.7522 kl=0.8339
  Step 10: reward=0.1283 loss=2.9006 kl=2.5260
  Step 11: reward=0.1536 loss=1.4558 kl=0.9562
  Step 12: reward=0.1202 loss=0.9074 kl=0.1948
  Step 13: reward=0.1444 loss=2.4207 kl=1.9259
  Step 14: reward=0.1125 loss=1.2522 kl=0.6268
  Step 15: reward=0.1201 loss=6.1217 kl=0.6550
  Step 16: reward=0.1264 loss=4.8321 kl=-0.6733
  Step 17: reward=0.1285 loss=1.3051 kl=0.9326
  Step 18: reward=0.1179 loss=3.8127 kl=-0.1548
  Step 19: reward=0.1303 loss=1.0047 kl=0.5716
  Step 20: reward=0.1355 loss=1.1048 kl=-0.3799
  Step 21: reward=0.1319 loss=2.1973 kl=1.0179
  Step 22: reward=0.1157 loss=1.8720 kl=1.4353
  Step 23: reward=0.1557 loss=2.2300 kl=0.5118
  Step 24: reward=0.1625 loss=13.9068 kl=0.1672
  Step 25: reward=0.1358 loss=1.9243 kl=0.8355
  Step 26: reward=0.1253 loss=6.8958 kl=2.1912
  Step 27: reward=0.1581 loss=1.2167 kl=0.9165
  Step 28: reward=0.1247 loss=3.2646 kl=0.2343
  Step 29: reward=0.1153 loss=1.1427 kl=0.6006
  Step 30: reward=0.1237 loss=4.4467 kl=0.3967
  Step 31: reward=0.1190 loss=2.9012 kl=-1.9859
  Step 32: reward=0.1242 loss=2.5647 kl=1.3013
  Step 33: reward=0.1200 loss=3.4973 kl=0.0205
  Step 34: reward=0.1264 loss=1.7092 kl=1.2182
  Step 35: reward=0.1281 loss=7.2778 kl=-0.1855
  Step 36: reward=0.1196 loss=1.0732 kl=-0.6223
  Step 37: reward=0.1255 loss=3.6267 kl=2.8332
  Step 38: reward=0.1249 loss=1.2713 kl=0.7533
  Step 39: reward=0.1287 loss=6353861.0000 kl=-1.3132
  Step 40: reward=0.1249 loss=1.9418 kl=1.1013
  Step 41: reward=0.1462 loss=0.3477 kl=-0.0105
  Step 42: reward=0.1271 loss=9.7255 kl=1.0970
  Step 43: reward=0.1261 loss=2.8309 kl=2.0309
  Step 44: reward=0.1400 loss=65.5131 kl=-0.3759
  Step 45: reward=0.1300 loss=7.1588 kl=0.7426
  Step 46: reward=0.1204 loss=2.5249 kl=2.0447
  Step 47: reward=0.1230 loss=2.2490 kl=1.8126
  Step 48: reward=0.1235 loss=1.2930 kl=0.6707
  Step 49: reward=0.1225 loss=9.5772 kl=0.8147
  Step 50: reward=0.1591 loss=0.9201 kl=0.7055
  Eval reward=0.6114 toxicity=0.0826
Epoch 9/10
  Step 01: reward=0.1316 loss=0.7138 kl=0.2602
  Step 02: reward=0.1257 loss=2.7005 kl=1.9315
  Step 03: reward=0.1294 loss=2.0920 kl=-0.0258
  Step 04: reward=0.1227 loss=1.2263 kl=0.2877
  Step 05: reward=0.1250 loss=1.0339 kl=0.6838
  Step 06: reward=0.1246 loss=2.7859 kl=1.7756
  Step 07: reward=0.1318 loss=0.6138 kl=0.2941
  Step 08: reward=0.1247 loss=3.1514 kl=0.9197
  Step 09: reward=0.1178 loss=27.1927 kl=-0.6297
  Step 10: reward=0.1145 loss=0.8837 kl=-0.1322
  Step 11: reward=0.1474 loss=6.9320 kl=-1.4113
  Step 12: reward=0.1522 loss=0.6639 kl=0.1774
  Step 13: reward=0.1285 loss=2.5331 kl=-0.6404
  Step 14: reward=0.1223 loss=1.6728 kl=0.1601
  Step 15: reward=0.1144 loss=1.8354 kl=1.3475
  Step 16: reward=0.1476 loss=1.7680 kl=0.2634
  Step 17: reward=0.1285 loss=7.8578 kl=-0.9800
  Step 18: reward=0.1188 loss=2.1676 kl=-0.5022
  Step 19: reward=0.1152 loss=0.7129 kl=-0.1108
  Step 20: reward=0.1280 loss=2.0075 kl=1.6493
  Step 21: reward=0.1513 loss=1.4164 kl=0.6412
  Step 22: reward=0.1295 loss=1.4767 kl=0.6399
  Step 23: reward=0.1318 loss=1.1754 kl=0.5046
  Step 24: reward=0.1265 loss=4.0520 kl=0.5284
  Step 25: reward=0.1185 loss=1.5536 kl=-0.5130
  Step 26: reward=0.1223 loss=0.6658 kl=0.3975
  Step 27: reward=0.1465 loss=0.5405 kl=-0.0028
  Step 28: reward=0.1579 loss=1002.4236 kl=-0.0693
  Step 29: reward=0.1303 loss=1.8545 kl=0.5193
  Step 30: reward=0.1523 loss=2.4830 kl=-0.5090
  Step 31: reward=0.1308 loss=3.4464 kl=0.9734
  Step 32: reward=0.1285 loss=2.5568 kl=-0.8436
  Step 33: reward=0.1429 loss=0.5123 kl=0.0954
  Step 34: reward=0.1286 loss=0.9472 kl=-0.0968
  Step 35: reward=0.1329 loss=1.1185 kl=0.3949
  Step 36: reward=0.1669 loss=75.8104 kl=-0.0472
  Step 37: reward=0.1146 loss=0.8646 kl=0.2049
  Step 38: reward=0.1244 loss=0.9608 kl=-0.2963
  Step 39: reward=0.1161 loss=1.6546 kl=0.8512
  Step 40: reward=0.1457 loss=0.9615 kl=0.6872
  Step 41: reward=0.1241 loss=1.8513 kl=0.9641
  Step 42: reward=0.1178 loss=0.9718 kl=-0.4271
  Step 43: reward=0.1222 loss=479.2435 kl=-1.2973
  Step 44: reward=0.1214 loss=62.4583 kl=0.2922
  Step 45: reward=0.1242 loss=289732487544832.0000 kl=-2.2515
  Step 46: reward=0.1283 loss=1.2325 kl=-0.7557
  Step 47: reward=0.1178 loss=7.0900 kl=-0.5061
  Step 48: reward=0.1138 loss=231913352593408.0000 kl=-1.7233
  Step 49: reward=0.1411 loss=15387337728.0000 kl=-1.6477
  Step 50: reward=0.1235 loss=0.6796 kl=-0.2194
  Eval reward=0.5970 toxicity=0.0709
Epoch 10/10
  Step 01: reward=0.1272 loss=50.6720 kl=0.3954
  Step 02: reward=0.1244 loss=14020.9580 kl=-1.3548
  Step 03: reward=0.1282 loss=1.2877 kl=0.9081
  Step 04: reward=0.1253 loss=11.9772 kl=0.4861
  Step 05: reward=0.1287 loss=7.0970 kl=0.5233
  Step 06: reward=0.1320 loss=6846335.0000 kl=-0.8268
  Step 07: reward=0.1363 loss=2.0154 kl=1.0315
  Step 08: reward=0.1361 loss=2.8627 kl=1.3105
  Step 09: reward=0.1237 loss=1.3795 kl=1.0005
  Step 10: reward=0.1179 loss=2.2222 kl=1.6426
  Step 11: reward=0.1174 loss=10.3251 kl=-0.0900
  Step 12: reward=0.1291 loss=1.8912 kl=-0.3315
  Step 13: reward=0.1267 loss=0.9418 kl=0.4227
  Step 14: reward=0.1263 loss=2.6450 kl=1.8248
  Step 15: reward=0.1301 loss=1.6643 kl=1.2183
  Step 16: reward=0.1224 loss=1.5500 kl=0.3305
  Step 17: reward=0.1318 loss=54.3819 kl=1.2923
  Step 18: reward=0.1247 loss=1.0665 kl=0.6517
  Step 19: reward=0.1276 loss=61.4925 kl=0.5927
  Step 20: reward=0.1156 loss=1.9268 kl=1.0196
  Step 21: reward=0.1234 loss=0.8741 kl=-0.1111
  Step 22: reward=0.1158 loss=0.8942 kl=0.0138
  Step 23: reward=0.1208 loss=1.6440 kl=0.5831
  Step 24: reward=0.1278 loss=10.2257 kl=0.5734
  Step 25: reward=0.1324 loss=1.0132 kl=0.5374
  Step 26: reward=0.1289 loss=0.6863 kl=-0.2517
  Step 27: reward=0.1280 loss=1.3915 kl=1.0259
  Step 28: reward=0.1279 loss=2.7180 kl=1.6383
  Step 29: reward=0.1294 loss=1.3228 kl=0.5321
  Step 30: reward=0.1288 loss=0.9758 kl=0.2937
  Step 31: reward=0.1228 loss=0.8595 kl=0.3638
  Step 32: reward=0.1246 loss=1.8800 kl=1.3955
  Step 33: reward=0.1222 loss=1.7619 kl=1.1364
  Step 34: reward=0.1352 loss=5.9929 kl=0.3264
  Step 35: reward=0.1243 loss=146.1638 kl=-0.9494
  Step 36: reward=0.1254 loss=21.4094 kl=-0.2173
  Step 37: reward=0.1227 loss=0.7826 kl=0.1854
  Step 38: reward=0.1243 loss=0.4720 kl=0.1313
  Step 39: reward=0.1252 loss=1.2191 kl=0.1386
  Step 40: reward=0.1249 loss=0.9418 kl=0.2145
  Step 41: reward=0.1266 loss=2.3572 kl=0.0643
  Step 42: reward=0.1272 loss=6.4235 kl=-0.2148
  Step 43: reward=0.1236 loss=1.4217 kl=0.7622
  Step 44: reward=0.1236 loss=0.9231 kl=0.5153
  Step 45: reward=0.1235 loss=5.6705 kl=-0.1977
  Step 46: reward=0.1274 loss=0.6682 kl=0.4257
  Step 47: reward=0.1218 loss=1.1462 kl=0.7109
  Step 48: reward=0.1214 loss=3.7644 kl=-0.3775
  Step 49: reward=0.1270 loss=1.9452 kl=-0.0736
  Step 50: reward=0.1547 loss=49.3368 kl=-1.0050
  Eval reward=0.6057 toxicity=0.0870
RLHF PPO policy saved to RL/full_run_jonly/bart-large/ppo_policy
RLHF model saved to RL/full_run_jonly/bart-large/final_model
Running inference over held-out set...
Generating test predictions:   0%|          | 0/62 [00:00<?, ?it/s]Generating test predictions:   2%|▏         | 1/62 [00:09<10:02,  9.88s/it]Generating test predictions:   3%|▎         | 2/62 [00:12<05:41,  5.69s/it]Generating test predictions:   5%|▍         | 3/62 [00:14<04:00,  4.07s/it]Generating test predictions:   6%|▋         | 4/62 [00:17<03:27,  3.58s/it]Generating test predictions:   8%|▊         | 5/62 [00:19<02:48,  2.95s/it]Generating test predictions:  10%|▉         | 6/62 [00:21<02:33,  2.73s/it]Generating test predictions:  11%|█▏        | 7/62 [00:25<02:52,  3.14s/it]Generating test predictions:  13%|█▎        | 8/62 [00:28<02:40,  2.98s/it]Generating test predictions:  15%|█▍        | 9/62 [00:30<02:22,  2.69s/it]Generating test predictions:  16%|█▌        | 10/62 [00:32<02:12,  2.55s/it]Generating test predictions:  18%|█▊        | 11/62 [00:34<02:05,  2.46s/it]Generating test predictions:  19%|█▉        | 12/62 [00:37<02:01,  2.42s/it]Generating test predictions:  21%|██        | 13/62 [00:39<01:51,  2.27s/it]Generating test predictions:  23%|██▎       | 14/62 [00:41<01:45,  2.20s/it]Generating test predictions:  24%|██▍       | 15/62 [00:43<01:39,  2.11s/it]Generating test predictions:  26%|██▌       | 16/62 [00:44<01:33,  2.04s/it]Generating test predictions:  27%|██▋       | 17/62 [00:46<01:29,  1.99s/it]Generating test predictions:  29%|██▉       | 18/62 [00:48<01:25,  1.94s/it]Generating test predictions:  31%|███       | 19/62 [00:50<01:20,  1.88s/it]Generating test predictions:  32%|███▏      | 20/62 [00:52<01:22,  1.96s/it]Generating test predictions:  34%|███▍      | 21/62 [00:54<01:19,  1.93s/it]Generating test predictions:  35%|███▌      | 22/62 [00:56<01:20,  2.00s/it]Generating test predictions:  37%|███▋      | 23/62 [00:59<01:29,  2.30s/it]Generating test predictions:  39%|███▊      | 24/62 [01:01<01:27,  2.30s/it]Generating test predictions:  40%|████      | 25/62 [01:04<01:23,  2.25s/it]Generating test predictions:  42%|████▏     | 26/62 [01:05<01:16,  2.14s/it]Generating test predictions:  44%|████▎     | 27/62 [01:08<01:14,  2.14s/it]Generating test predictions:  45%|████▌     | 28/62 [01:10<01:12,  2.14s/it]Generating test predictions:  47%|████▋     | 29/62 [01:11<01:07,  2.04s/it]Generating test predictions:  48%|████▊     | 30/62 [01:14<01:04,  2.03s/it]Generating test predictions:  50%|█████     | 31/62 [01:16<01:03,  2.05s/it]Generating test predictions:  52%|█████▏    | 32/62 [01:18<01:05,  2.17s/it]Generating test predictions:  53%|█████▎    | 33/62 [01:20<01:01,  2.11s/it]Generating test predictions:  55%|█████▍    | 34/62 [01:22<00:57,  2.04s/it]Generating test predictions:  56%|█████▋    | 35/62 [01:25<01:01,  2.26s/it]Generating test predictions:  58%|█████▊    | 36/62 [01:27<00:59,  2.28s/it]Generating test predictions:  60%|█████▉    | 37/62 [01:29<00:58,  2.32s/it]Generating test predictions:  61%|██████▏   | 38/62 [01:31<00:53,  2.23s/it]Generating test predictions:  63%|██████▎   | 39/62 [01:33<00:48,  2.10s/it]Generating test predictions:  65%|██████▍   | 40/62 [01:36<00:50,  2.30s/it]Generating test predictions:  66%|██████▌   | 41/62 [01:38<00:46,  2.24s/it]Generating test predictions:  68%|██████▊   | 42/62 [01:40<00:43,  2.17s/it]Generating test predictions:  69%|██████▉   | 43/62 [01:42<00:41,  2.19s/it]Generating test predictions:  71%|███████   | 44/62 [01:44<00:39,  2.18s/it]Generating test predictions:  73%|███████▎  | 45/62 [01:46<00:36,  2.12s/it]Generating test predictions:  74%|███████▍  | 46/62 [01:49<00:33,  2.11s/it]Generating test predictions:  76%|███████▌  | 47/62 [01:50<00:29,  1.97s/it]Generating test predictions:  77%|███████▋  | 48/62 [01:53<00:29,  2.10s/it]Generating test predictions:  79%|███████▉  | 49/62 [01:55<00:27,  2.08s/it]Generating test predictions:  81%|████████  | 50/62 [01:57<00:24,  2.03s/it]Generating test predictions:  82%|████████▏ | 51/62 [01:58<00:21,  1.99s/it]Generating test predictions:  84%|████████▍ | 52/62 [02:01<00:20,  2.04s/it]Generating test predictions:  85%|████████▌ | 53/62 [02:02<00:17,  2.00s/it]Generating test predictions:  87%|████████▋ | 54/62 [02:05<00:16,  2.04s/it]Generating test predictions:  89%|████████▊ | 55/62 [02:06<00:13,  1.98s/it]Generating test predictions:  90%|█████████ | 56/62 [02:08<00:11,  1.98s/it]Generating test predictions:  92%|█████████▏| 57/62 [02:10<00:09,  1.99s/it]Generating test predictions:  94%|█████████▎| 58/62 [02:12<00:07,  1.99s/it]Generating test predictions:  95%|█████████▌| 59/62 [02:14<00:05,  1.99s/it]Generating test predictions:  97%|█████████▋| 60/62 [02:16<00:03,  1.98s/it]Generating test predictions:  98%|█████████▊| 61/62 [02:18<00:01,  1.94s/it]Generating test predictions: 100%|██████████| 62/62 [02:20<00:00,  1.90s/it]                                                                            Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
That's 100 lines that end in a tokenized period ('.')
It looks like you forgot to detokenize your test data, which may hurt your score.
If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
Saved predictions to RL/full_run_jonly/bart-large/test_results.tsv
Computing ParaDetox metrics...
Loaded 1973 examples with model outputs.
Using device: cpu

Computing BLEU...
Computing Style Accuracy (STA)...
Computing Content Preservation (SIM)...
Batches:   0%|          | 0/31 [00:00<?, ?it/s]Batches:   3%|▎         | 1/31 [00:00<00:27,  1.09it/s]Batches:   6%|▋         | 2/31 [00:01<00:13,  2.17it/s]Batches:  10%|▉         | 3/31 [00:01<00:08,  3.28it/s]Batches:  13%|█▎        | 4/31 [00:01<00:06,  4.24it/s]Batches:  16%|█▌        | 5/31 [00:01<00:04,  5.25it/s]Batches:  19%|█▉        | 6/31 [00:01<00:04,  6.07it/s]Batches:  26%|██▌       | 8/31 [00:01<00:02,  8.82it/s]Batches:  32%|███▏      | 10/31 [00:01<00:02,  9.80it/s]Batches:  39%|███▊      | 12/31 [00:02<00:01,  9.85it/s]Batches:  45%|████▌     | 14/31 [00:02<00:02,  6.99it/s]Batches:  48%|████▊     | 15/31 [00:02<00:02,  7.23it/s]Batches:  55%|█████▍    | 17/31 [00:02<00:01,  9.33it/s]Batches:  61%|██████▏   | 19/31 [00:02<00:01, 10.55it/s]Batches:  68%|██████▊   | 21/31 [00:02<00:00, 11.57it/s]Batches:  74%|███████▍  | 23/31 [00:03<00:00, 10.87it/s]Batches:  81%|████████  | 25/31 [00:03<00:00, 11.88it/s]Batches:  87%|████████▋ | 27/31 [00:03<00:00, 12.53it/s]Batches:  94%|█████████▎| 29/31 [00:03<00:00, 11.37it/s]Batches: 100%|██████████| 31/31 [00:03<00:00, 12.18it/s]Batches: 100%|██████████| 31/31 [00:03<00:00,  8.14it/s]
Batches:   0%|          | 0/31 [00:00<?, ?it/s]Batches:   6%|▋         | 2/31 [00:00<00:01, 14.61it/s]Batches:  13%|█▎        | 4/31 [00:00<00:01, 14.05it/s]Batches:  19%|█▉        | 6/31 [00:00<00:01, 14.74it/s]Batches:  26%|██▌       | 8/31 [00:00<00:01, 15.84it/s]Batches:  32%|███▏      | 10/31 [00:00<00:01, 14.56it/s]Batches:  39%|███▊      | 12/31 [00:00<00:01, 16.02it/s]Batches:  45%|████▌     | 14/31 [00:00<00:00, 17.11it/s]Batches:  55%|█████▍    | 17/31 [00:01<00:00, 18.93it/s]Batches:  65%|██████▍   | 20/31 [00:01<00:00, 20.05it/s]Batches:  74%|███████▍  | 23/31 [00:01<00:00, 19.78it/s]Batches:  81%|████████  | 25/31 [00:01<00:00, 18.92it/s]Batches:  90%|█████████ | 28/31 [00:01<00:00, 21.13it/s]Batches: 100%|██████████| 31/31 [00:02<00:00,  9.91it/s]Batches: 100%|██████████| 31/31 [00:02<00:00, 14.33it/s]
Computing Fluency (FL)...

=== ParaDetox-style Metrics ===
BLEU:  56.48
STA :  0.950
SIM :  0.828
FL  :  0.804
J   :  0.633
Metrics written to RL/full_run_jonly/bart-large/metrics.txt
