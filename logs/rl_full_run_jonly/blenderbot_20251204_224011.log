Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Using device: mps
Loading policy initialization from TRAIN/blenderbot/final_model
Epoch 1/10
  Step 01: reward=0.1177 loss=389824.5312 kl=-0.5285
  Step 02: reward=0.1191 loss=1.7734 kl=4.9944
  Step 03: reward=0.1171 loss=1.6850 kl=4.2452
  Step 04: reward=0.1172 loss=0.5490 kl=0.4192
  Step 05: reward=0.1156 loss=1.6525 kl=-0.0334
  Step 06: reward=0.1164 loss=0.6456 kl=-0.7860
  Step 07: reward=0.1128 loss=5.1563 kl=-0.0848
  Step 08: reward=0.1230 loss=0.4975 kl=-0.2565
  Step 09: reward=0.1195 loss=12.3998 kl=-0.1647
  Step 10: reward=0.1175 loss=0.9978 kl=-0.0192
  Step 11: reward=0.1163 loss=1.0866 kl=-0.5883
  Step 12: reward=0.1222 loss=0.7781 kl=0.9054
  Step 13: reward=0.1208 loss=1.4531 kl=2.1068
  Step 14: reward=0.1228 loss=0.3814 kl=0.2169
  Step 15: reward=0.1176 loss=1.1723 kl=1.4229
  Step 16: reward=0.1152 loss=0.5457 kl=0.0049
  Step 17: reward=0.1232 loss=7.3066 kl=-0.3550
  Step 18: reward=0.1194 loss=0.5913 kl=0.3153
  Step 19: reward=0.1206 loss=0.4119 kl=-0.0018
  Step 20: reward=0.1069 loss=0.6020 kl=0.0237
  Step 21: reward=0.1272 loss=0.4443 kl=0.5945
  Step 22: reward=0.1202 loss=3760545857536.0000 kl=-2.4343
  Step 23: reward=0.1218 loss=2.1591 kl=-0.4899
  Step 24: reward=0.1213 loss=1.8336 kl=-0.0944
  Step 25: reward=0.1208 loss=102.5680 kl=-1.2218
  Step 26: reward=0.1169 loss=0.8732 kl=0.0743
  Step 27: reward=0.1182 loss=156485.7031 kl=-1.9897
  Step 28: reward=0.1126 loss=1.3238 kl=-2.4842
  Step 29: reward=0.1189 loss=0.8348 kl=0.0533
  Step 30: reward=0.1163 loss=0.9011 kl=0.2646
  Step 31: reward=0.1181 loss=1.1299 kl=0.0988
  Step 32: reward=0.1211 loss=1.1148 kl=-0.9065
  Step 33: reward=0.1221 loss=0.9098 kl=-0.5361
  Step 34: reward=0.1212 loss=0.5283 kl=0.2991
  Step 35: reward=0.1174 loss=1.2093 kl=-0.8376
  Step 36: reward=0.1213 loss=5.2780 kl=1.8560
  Step 37: reward=0.1218 loss=1.4066 kl=2.1220
  Step 38: reward=0.1158 loss=0.9902 kl=1.0650
  Step 39: reward=0.1152 loss=0.5480 kl=0.4437
  Step 40: reward=0.1159 loss=1.4326 kl=1.1211
  Step 41: reward=0.1184 loss=2.2693 kl=0.5166
  Step 42: reward=0.1210 loss=0.9179 kl=-0.0626
  Step 43: reward=0.1238 loss=0.4794 kl=0.2282
  Step 44: reward=0.1193 loss=3.1956 kl=1.2388
  Step 45: reward=0.1203 loss=14.0603 kl=-1.9362
  Step 46: reward=0.1217 loss=6.9944 kl=0.7244
  Step 47: reward=0.1211 loss=33.9404 kl=-0.8288
  Step 48: reward=0.1159 loss=1.0086 kl=0.6116
  Step 49: reward=0.1195 loss=1.5883 kl=-0.9103
  Step 50: reward=0.1166 loss=0.7169 kl=-0.2006
  Eval reward=0.5760 toxicity=0.0903
Epoch 2/10
  Step 01: reward=0.1258 loss=2.1199 kl=-0.1847
  Step 02: reward=0.1240 loss=1.7753 kl=0.5838
  Step 03: reward=0.1172 loss=46381699072.0000 kl=-1.6043
  Step 04: reward=0.1185 loss=19.0324 kl=-0.2194
  Step 05: reward=0.1228 loss=1.7157 kl=1.3817
  Step 06: reward=0.1195 loss=1.7745 kl=0.7168
  Step 07: reward=0.1135 loss=247.2969 kl=-0.9480
  Step 08: reward=0.1205 loss=1.5346 kl=1.0988
  Step 09: reward=0.1186 loss=1.1263 kl=0.6762
  Step 10: reward=0.1238 loss=12.7863 kl=0.2174
  Step 11: reward=0.1234 loss=1.6362 kl=0.9782
  Step 12: reward=0.1272 loss=0.7624 kl=0.3971
  Step 13: reward=0.1178 loss=1.0492 kl=0.2140
  Step 14: reward=0.1163 loss=1.2668 kl=0.8868
  Step 15: reward=0.1219 loss=1.0712 kl=0.7071
  Step 16: reward=0.1236 loss=8351.3037 kl=-0.9080
  Step 17: reward=0.1144 loss=1.0644 kl=0.7259
  Step 18: reward=0.1194 loss=40282772.0000 kl=-2.1195
  Step 19: reward=0.1160 loss=2.0400 kl=-0.1451
  Step 20: reward=0.1263 loss=1.0125 kl=0.0933
  Step 21: reward=0.1193 loss=230694454296576.0000 kl=-3.1802
  Step 22: reward=0.1167 loss=1.6095 kl=0.0118
  Step 23: reward=0.1155 loss=1.6289 kl=0.7442
  Step 24: reward=0.1175 loss=0.7725 kl=0.3582
  Step 25: reward=0.1223 loss=594230.6250 kl=-1.8972
  Step 26: reward=0.1331 loss=1.0132 kl=0.1312
  Step 27: reward=0.1129 loss=1.7697 kl=-0.3877
  Step 28: reward=0.1225 loss=0.4592 kl=0.0288
  Step 29: reward=0.1214 loss=0.8565 kl=0.2093
  Step 30: reward=0.1211 loss=2.0901 kl=-1.7092
  Step 31: reward=0.1168 loss=1.3848 kl=-0.3758
  Step 32: reward=0.1207 loss=1.2411 kl=0.0882
  Step 33: reward=0.1184 loss=3.2327 kl=0.4670
  Step 34: reward=0.1211 loss=1.8541 kl=0.2119
  Step 35: reward=0.1182 loss=1.5534 kl=0.2337
  Step 36: reward=0.1199 loss=1.0371 kl=0.3779
  Step 37: reward=0.1145 loss=0.9065 kl=-0.2921
  Step 38: reward=0.1167 loss=4.0819 kl=0.3343
  Step 39: reward=0.1242 loss=0.6369 kl=0.0120
  Step 40: reward=0.1220 loss=0.9177 kl=-0.3908
  Step 41: reward=0.1133 loss=2.7085 kl=-0.0641
  Step 42: reward=0.1214 loss=1.9258 kl=-0.2849
  Step 43: reward=0.1010 loss=1.5649 kl=0.9294
  Step 44: reward=0.1136 loss=0.8078 kl=0.4920
  Step 45: reward=0.1226 loss=3.2135 kl=2.5665
  Step 46: reward=0.1248 loss=2.5634 kl=-0.3386
  Step 47: reward=0.1213 loss=1.3343 kl=0.6375
  Step 48: reward=0.1167 loss=1.3824 kl=-0.8568
  Step 49: reward=0.1201 loss=1.8609 kl=0.2333
  Step 50: reward=0.1223 loss=3.0261 kl=-1.1362
  Eval reward=0.5783 toxicity=0.0806
Epoch 3/10
  Step 01: reward=0.1204 loss=2.0995 kl=1.4188
  Step 02: reward=0.1170 loss=5.0785 kl=0.7242
  Step 03: reward=0.1129 loss=2044.3284 kl=1.4667
  Step 04: reward=0.1174 loss=1.5206 kl=1.0611
  Step 05: reward=0.1162 loss=0.9693 kl=0.6031
  Step 06: reward=0.1212 loss=1.1317 kl=0.5487
  Step 07: reward=0.1186 loss=1.7920 kl=0.4790
  Step 08: reward=0.1144 loss=2.5651 kl=1.3873
  Step 09: reward=0.1250 loss=3.6690 kl=2.9974
  Step 10: reward=0.1360 loss=1.1073 kl=0.2477
  Step 11: reward=0.1153 loss=1.2464 kl=0.5684
  Step 12: reward=0.1220 loss=40.4265 kl=0.6687
  Step 13: reward=0.1241 loss=2.3610 kl=0.2562
  Step 14: reward=0.1198 loss=0.8140 kl=0.4086
  Step 15: reward=0.1111 loss=3.1194 kl=0.8579
  Step 16: reward=0.1228 loss=250.3350 kl=0.5174
  Step 17: reward=0.1211 loss=0.7768 kl=0.2740
  Step 18: reward=0.1148 loss=1.3026 kl=-0.8092
  Step 19: reward=0.1533 loss=0.4906 kl=0.0579
  Step 20: reward=0.1151 loss=2.2949 kl=-0.7589
  Step 21: reward=0.1103 loss=14.7833 kl=1.2512
  Step 22: reward=0.1199 loss=1.1013 kl=0.3218
  Step 23: reward=0.1210 loss=1.0982 kl=-0.5166
  Step 24: reward=0.1162 loss=1.0120 kl=-0.1171
  Step 25: reward=0.1179 loss=0.8203 kl=0.1215
  Step 26: reward=0.1168 loss=1.1074 kl=0.0067
  Step 27: reward=0.1110 loss=0.6357 kl=0.2006
  Step 28: reward=0.1121 loss=0.7979 kl=0.1315
  Step 29: reward=0.1239 loss=1.2849 kl=-0.3111
  Step 30: reward=0.1222 loss=0.4276 kl=-0.0670
  Step 31: reward=0.1206 loss=0.8817 kl=0.4292
  Step 32: reward=0.1377 loss=1.6978 kl=-1.9525
  Step 33: reward=0.1216 loss=9.0956 kl=-1.2596
  Step 34: reward=0.1209 loss=0.7458 kl=0.4744
  Step 35: reward=0.1196 loss=0.7427 kl=0.4139
  Step 36: reward=0.1215 loss=3.3439 kl=-0.0515
  Step 37: reward=0.1242 loss=0.7447 kl=0.1628
  Step 38: reward=0.1180 loss=1.1553 kl=-0.4342
  Step 39: reward=0.1201 loss=1.4366 kl=-0.4171
  Step 40: reward=0.1223 loss=0.6998 kl=-0.3193
  Step 41: reward=0.1280 loss=1.3143 kl=0.2156
  Step 42: reward=0.1172 loss=0.7455 kl=-0.4038
  Step 43: reward=0.1214 loss=1.4150 kl=1.1352
  Step 44: reward=0.1259 loss=0.3615 kl=0.1139
  Step 45: reward=0.1187 loss=1.8091 kl=-0.7954
  Step 46: reward=0.1210 loss=0.5295 kl=0.1671
  Step 47: reward=0.1118 loss=163760848.0000 kl=-2.1806
  Step 48: reward=0.1241 loss=0.5990 kl=-0.4187
  Step 49: reward=0.1156 loss=10078090.0000 kl=-1.4021
  Step 50: reward=0.1167 loss=0.5147 kl=0.2630
  Eval reward=0.5776 toxicity=0.0837
Epoch 4/10
  Step 01: reward=0.1205 loss=3.5308 kl=1.5873
  Step 02: reward=0.1141 loss=1.0148 kl=-0.1773
  Step 03: reward=0.1169 loss=2.2079 kl=0.1415
  Step 04: reward=0.1253 loss=2.1675 kl=-0.0341
  Step 05: reward=0.1170 loss=0.8179 kl=-0.2752
  Step 06: reward=0.1144 loss=0.9484 kl=0.3542
  Step 07: reward=0.1239 loss=1.2239 kl=-0.3184
  Step 08: reward=0.1226 loss=1.0253 kl=-0.2628
  Step 09: reward=0.1217 loss=0.4995 kl=0.0657
  Step 10: reward=0.1197 loss=1358.6871 kl=-0.2276
  Step 11: reward=0.1184 loss=2.2439 kl=2.2651
  Step 12: reward=0.1200 loss=1.6117 kl=1.0609
  Step 13: reward=0.1241 loss=3.8384 kl=2.3729
  Step 14: reward=0.1226 loss=1.4876 kl=0.9441
  Step 15: reward=0.1128 loss=1.5907 kl=0.7381
  Step 16: reward=0.1083 loss=1.3716 kl=0.7516
  Step 17: reward=0.1220 loss=1.2259 kl=0.6079
  Step 18: reward=0.1169 loss=1.1485 kl=0.1672
  Step 19: reward=0.1308 loss=38.6175 kl=0.1037
  Step 20: reward=0.1236 loss=1.9438 kl=0.7912
  Step 21: reward=0.1205 loss=1.4774 kl=0.7028
  Step 22: reward=0.1181 loss=1.4157 kl=0.6612
  Step 23: reward=0.1199 loss=1.2331 kl=0.7834
  Step 24: reward=0.1174 loss=3681.2351 kl=-0.3846
  Step 25: reward=0.1192 loss=8094945.0000 kl=-1.9022
  Step 26: reward=0.1209 loss=2596109.7500 kl=-6.0935
  Step 27: reward=0.1192 loss=24.5552 kl=-1.0586
  Step 28: reward=0.1432 loss=0.7220 kl=-0.2871
  Step 29: reward=0.1183 loss=2520.7141 kl=-0.8428
  Step 30: reward=0.1197 loss=4077182517248.0000 kl=-2.8958
  Step 31: reward=0.1405 loss=0.9694 kl=-0.3434
  Step 32: reward=0.1222 loss=1.8648 kl=-0.1356
  Step 33: reward=0.1198 loss=1.8817 kl=1.3614
  Step 34: reward=0.1215 loss=1.9724 kl=-0.6199
  Step 35: reward=0.1141 loss=0.9085 kl=0.4748
  Step 36: reward=0.1199 loss=0.6580 kl=0.2399
  Step 37: reward=0.1211 loss=42.4308 kl=1.0137
  Step 38: reward=0.1203 loss=0.7835 kl=0.3520
  Step 39: reward=0.1226 loss=0.6937 kl=-0.0600
  Step 40: reward=0.1158 loss=0.6288 kl=0.1769
  Step 41: reward=0.1162 loss=0.9061 kl=-0.0092
  Step 42: reward=0.1233 loss=1.3957 kl=0.8890
  Step 43: reward=0.1221 loss=0.5138 kl=0.2224
  Step 44: reward=0.1167 loss=18.3998 kl=-0.7499
  Step 45: reward=0.1363 loss=1.1791 kl=0.4045
  Step 46: reward=0.1134 loss=6.3705 kl=-0.9293
  Step 47: reward=0.1225 loss=6.1106 kl=-0.7764
  Step 48: reward=0.1109 loss=0.7314 kl=-0.2833
  Step 49: reward=0.1266 loss=1.3406 kl=-0.3902
  Step 50: reward=0.1157 loss=0.5582 kl=0.1498
  Eval reward=0.5788 toxicity=0.0739
Epoch 5/10
  Step 01: reward=0.1237 loss=0.7168 kl=0.3515
  Step 02: reward=0.1184 loss=1.0081 kl=0.2264
  Step 03: reward=0.1221 loss=2.2506 kl=-1.5077
  Step 04: reward=0.1181 loss=1.3015 kl=0.9763
  Step 05: reward=0.1206 loss=18.4243 kl=-0.5046
  Step 06: reward=0.1425 loss=0.5968 kl=-0.2300
  Step 07: reward=0.1172 loss=10.7448 kl=-0.8484
  Step 08: reward=0.1330 loss=1.4449 kl=-1.0077
  Step 09: reward=0.1186 loss=1.1936 kl=0.0333
  Step 10: reward=0.1247 loss=1.0379 kl=0.2472
  Step 11: reward=0.1177 loss=0.8178 kl=0.2937
  Step 12: reward=0.1222 loss=1.3448 kl=-0.1427
  Step 13: reward=0.1145 loss=1.8918 kl=-1.3384
  Step 14: reward=0.1219 loss=7585.9341 kl=-2.7247
  Step 15: reward=0.1161 loss=0.9290 kl=0.4689
  Step 16: reward=0.1155 loss=1.1418 kl=-0.7152
  Step 17: reward=0.1199 loss=159.6431 kl=0.0765
  Step 18: reward=0.1189 loss=1.3101 kl=0.8476
  Step 19: reward=0.1202 loss=2.1743 kl=0.3088
  Step 20: reward=0.1158 loss=2.8891 kl=-2.2126
  Step 21: reward=0.1136 loss=1.0886 kl=0.2220
  Step 22: reward=0.1196 loss=0.5849 kl=0.1142
  Step 23: reward=0.1231 loss=1.5910 kl=1.1429
  Step 24: reward=0.1183 loss=0.5892 kl=-0.1146
  Step 25: reward=0.1158 loss=0.6844 kl=0.1856
  Step 26: reward=0.1174 loss=1.4249 kl=1.0758
  Step 27: reward=0.1202 loss=1.0510 kl=0.6609
  Step 28: reward=0.1185 loss=1.5914 kl=-0.3904
  Step 29: reward=0.1190 loss=1.4745 kl=0.1750
  Step 30: reward=0.1247 loss=1.5891 kl=1.0673
  Step 31: reward=0.1393 loss=253.4461 kl=-0.3030
  Step 32: reward=0.1207 loss=3.4782 kl=0.0962
  Step 33: reward=0.1226 loss=1.4937 kl=-0.8709
  Step 34: reward=0.1140 loss=2.4483 kl=-0.0547
  Step 35: reward=0.1131 loss=366.0363 kl=-0.8064
  Step 36: reward=0.1244 loss=2.4240 kl=2.1024
  Step 37: reward=0.1254 loss=1.2588 kl=0.4661
  Step 38: reward=0.1138 loss=91587.0000 kl=-0.3383
  Step 39: reward=0.1156 loss=0.7549 kl=0.3710
  Step 40: reward=0.1209 loss=13.4005 kl=1.4005
  Step 41: reward=0.1175 loss=1.1521 kl=-0.0325
  Step 42: reward=0.1200 loss=1.3728 kl=0.4904
  Step 43: reward=0.1113 loss=4.1513 kl=0.9297
  Step 44: reward=0.1185 loss=1.5381 kl=0.8367
  Step 45: reward=0.1189 loss=0.8776 kl=0.2796
  Step 46: reward=0.1255 loss=0.8434 kl=0.0775
  Step 47: reward=0.1136 loss=2804.8848 kl=-1.5211
  Step 48: reward=0.1225 loss=1.1920 kl=0.3164
  Step 49: reward=0.1160 loss=0.9808 kl=-0.2671
  Step 50: reward=0.1245 loss=0.4303 kl=0.0520
  Eval reward=0.5756 toxicity=0.0772
Epoch 6/10
  Step 01: reward=0.1244 loss=5.8172 kl=-2.6008
  Step 02: reward=0.1183 loss=2.4566 kl=-1.0149
  Step 03: reward=0.1235 loss=2.9809 kl=0.0560
  Step 04: reward=0.1190 loss=0.7274 kl=-0.1803
  Step 05: reward=0.1183 loss=3.1706 kl=0.3148
  Step 06: reward=0.1176 loss=0.8582 kl=-0.1106
  Step 07: reward=0.1154 loss=7.1851 kl=-0.4023
  Step 08: reward=0.1079 loss=28.5884 kl=1.6631
  Step 09: reward=0.1207 loss=1.9519 kl=-0.4486
  Step 10: reward=0.1175 loss=1.0836 kl=0.8741
  Step 11: reward=0.1136 loss=0.9252 kl=0.3381
  Step 12: reward=0.1210 loss=0.5384 kl=0.0013
  Step 13: reward=0.1191 loss=1.3124 kl=0.6402
  Step 14: reward=0.1219 loss=8.6972 kl=7.2158
  Step 15: reward=0.1175 loss=1.4243 kl=0.5778
  Step 16: reward=0.1177 loss=2.4170 kl=1.7858
  Step 17: reward=0.1223 loss=0.4627 kl=0.0972
  Step 18: reward=0.1136 loss=0.7004 kl=0.1906
  Step 19: reward=0.1189 loss=4.6510 kl=-3.4919
  Step 20: reward=0.1166 loss=16.5961 kl=-1.2444
  Step 21: reward=0.1134 loss=570074297532416.0000 kl=-6.6244
  Step 22: reward=0.1139 loss=0.4097 kl=-0.0512
  Step 23: reward=0.1230 loss=0.3890 kl=0.0698
  Step 24: reward=0.1253 loss=0.6591 kl=0.3722
  Step 25: reward=0.1213 loss=88.3611 kl=-0.4890
  Step 26: reward=0.1170 loss=1.7625 kl=-0.4226
  Step 27: reward=0.1215 loss=0.8063 kl=-0.0395
  Step 28: reward=0.1204 loss=1.1002 kl=-0.7049
  Step 29: reward=0.1199 loss=5.9582 kl=-0.0387
  Step 30: reward=0.1211 loss=119.3949 kl=0.2027
  Step 31: reward=0.1165 loss=0.8426 kl=0.5937
  Step 32: reward=0.1212 loss=3.1280 kl=2.7466
  Step 33: reward=0.1191 loss=3.1784 kl=2.1348
  Step 34: reward=0.1138 loss=0.6862 kl=-0.0331
  Step 35: reward=0.1176 loss=1.1670 kl=0.6601
  Step 36: reward=0.1185 loss=1.3919 kl=0.9361
  Step 37: reward=0.1226 loss=1.0104 kl=0.4526
  Step 38: reward=0.1308 loss=1.1828 kl=-0.5554
  Step 39: reward=0.1216 loss=169.8450 kl=2.7870
  Step 40: reward=0.1227 loss=681.6159 kl=-0.0087
  Step 41: reward=0.1203 loss=1.0631 kl=-0.5400
  Step 42: reward=0.1215 loss=2.0684 kl=-0.5581
  Step 43: reward=0.1178 loss=1.2197 kl=0.8738
  Step 44: reward=0.1229 loss=1.6660 kl=1.0761
  Step 45: reward=0.1121 loss=2.2425 kl=1.5456
  Step 46: reward=0.1161 loss=1.1891 kl=0.7217
  Step 47: reward=0.1196 loss=0.6587 kl=-0.2507
  Step 48: reward=0.1208 loss=3.6913 kl=-0.6586
  Step 49: reward=0.1049 loss=5.5984 kl=-0.3399
  Step 50: reward=0.1160 loss=1.3628 kl=-0.1576
  Eval reward=0.5751 toxicity=0.0754
Epoch 7/10
  Step 01: reward=0.1270 loss=0.9548 kl=0.5174
  Step 02: reward=0.1220 loss=0.7849 kl=0.1947
  Step 03: reward=0.1200 loss=1.3361 kl=0.2174
  Step 04: reward=0.1254 loss=3.1126 kl=-2.4977
  Step 05: reward=0.1216 loss=22.8263 kl=-0.7316
  Step 06: reward=0.1207 loss=2.4554 kl=-1.2715
  Step 07: reward=0.1112 loss=2866.1047 kl=0.3939
  Step 08: reward=0.1161 loss=0.6317 kl=-0.0995
  Step 09: reward=0.1149 loss=130.6564 kl=-0.7479
  Step 10: reward=0.1178 loss=0.7357 kl=-0.1441
  Step 11: reward=0.1180 loss=1.3942 kl=0.7420
  Step 12: reward=0.1132 loss=1.4117 kl=0.9700
  Step 13: reward=0.1282 loss=1.6432 kl=1.0070
  Step 14: reward=0.1174 loss=4.8029 kl=1.2033
  Step 15: reward=0.1171 loss=0.9230 kl=0.3476
  Step 16: reward=0.1204 loss=32.6124 kl=0.1422
  Step 17: reward=0.1187 loss=1.3668 kl=0.9472
  Step 18: reward=0.1238 loss=1.3248 kl=-0.0890
  Step 19: reward=0.1173 loss=6.9570 kl=4.9673
  Step 20: reward=0.1200 loss=0.9555 kl=-0.1627
  Step 21: reward=0.1158 loss=0.5780 kl=-0.3152
  Step 22: reward=0.1206 loss=1.6474 kl=1.0902
  Step 23: reward=0.1199 loss=0.8451 kl=0.1549
  Step 24: reward=0.1329 loss=1.5540 kl=-0.3380
  Step 25: reward=0.1163 loss=0.7066 kl=-0.2573
  Step 26: reward=0.1168 loss=1.5686 kl=1.0731
  Step 27: reward=0.1189 loss=1.6119 kl=1.0377
  Step 28: reward=0.1207 loss=1.8383 kl=0.1034
  Step 29: reward=0.1174 loss=3.2962 kl=2.8191
  Step 30: reward=0.1255 loss=1.0518 kl=0.4267
  Step 31: reward=0.1226 loss=1.7076 kl=0.5109
  Step 32: reward=0.1196 loss=4027.1211 kl=-0.1209
  Step 33: reward=0.1233 loss=0.9565 kl=0.5626
  Step 34: reward=0.1235 loss=1.6700 kl=0.9643
  Step 35: reward=0.1108 loss=4.4444 kl=-0.9852
  Step 36: reward=0.1156 loss=0.8490 kl=0.4619
  Step 37: reward=0.1228 loss=1.8102 kl=1.3516
  Step 38: reward=0.1212 loss=2.1134 kl=-0.7362
  Step 39: reward=0.1187 loss=440.0456 kl=-1.1102
  Step 40: reward=0.1259 loss=40415306711040.0000 kl=-2.4670
  Step 41: reward=0.1205 loss=1.4597 kl=-0.9070
  Step 42: reward=0.1180 loss=4.3217 kl=-0.7362
  Step 43: reward=0.1206 loss=1.0311 kl=-0.2673
  Step 44: reward=0.1166 loss=0.4343 kl=0.0742
  Step 45: reward=0.1163 loss=0.3062 kl=-0.0176
  Step 46: reward=0.1124 loss=1.2693 kl=-0.5481
  Step 47: reward=0.1198 loss=0.7510 kl=-0.3011
  Step 48: reward=0.1208 loss=1.0462 kl=-0.6888
  Step 49: reward=0.1190 loss=527.0944 kl=-0.7809
  Step 50: reward=0.1206 loss=0.9363 kl=-0.5577
  Eval reward=0.5739 toxicity=0.0871
Epoch 8/10
  Step 01: reward=0.1199 loss=0.8973 kl=0.2947
  Step 02: reward=0.1211 loss=2.1804 kl=-0.3921
  Step 03: reward=0.1197 loss=0.9491 kl=-0.1030
  Step 04: reward=0.1235 loss=0.7695 kl=0.3506
  Step 05: reward=0.1239 loss=1.0946 kl=-0.0497
  Step 06: reward=0.1115 loss=0.5397 kl=-0.3298
  Step 07: reward=0.1204 loss=1599781.5000 kl=-1.2085
  Step 08: reward=0.1229 loss=3.3899 kl=0.6138
  Step 09: reward=0.1226 loss=1.2878 kl=0.8725
  Step 10: reward=0.1180 loss=1.0708 kl=0.5224
  Step 11: reward=0.1144 loss=1.2799 kl=-0.5470
  Step 12: reward=0.1185 loss=5.3228 kl=-0.5886
  Step 13: reward=0.1154 loss=4250.2896 kl=-0.2371
  Step 14: reward=0.1226 loss=1584.7046 kl=1.4018
  Step 15: reward=0.1161 loss=584.0543 kl=0.3412
  Step 16: reward=0.1118 loss=1.3832 kl=0.9390
  Step 17: reward=0.1130 loss=1.4815 kl=1.0787
  Step 18: reward=0.1163 loss=115.5356 kl=0.7049
  Step 19: reward=0.1234 loss=1.5727 kl=1.1462
  Step 20: reward=0.1180 loss=50.5803 kl=0.7985
  Step 21: reward=0.1132 loss=3.7130 kl=1.3833
  Step 22: reward=0.1218 loss=7.9460 kl=7.3689
  Step 23: reward=0.1219 loss=1.7704 kl=1.2590
  Step 24: reward=0.1211 loss=4.9319 kl=2.1312
  Step 25: reward=0.1664 loss=0.9810 kl=0.7022
  Step 26: reward=0.1121 loss=6.7609 kl=1.4019
  Step 27: reward=0.1232 loss=0.8790 kl=0.5050
  Step 28: reward=0.1214 loss=1.5244 kl=0.9204
  Step 29: reward=0.1236 loss=73361482887074938880.0000 kl=-2.0470
  Step 30: reward=0.1226 loss=0.6745 kl=-0.1817
  Step 31: reward=0.1167 loss=2.0034 kl=1.4925
  Step 32: reward=0.1225 loss=3.8052 kl=-1.9507
  Step 33: reward=0.1182 loss=0.8382 kl=-0.2933
  Step 34: reward=0.1216 loss=39158.9297 kl=-0.0185
  Step 35: reward=0.1224 loss=0.5356 kl=0.1536
  Step 36: reward=0.1420 loss=0.9976 kl=-0.1128
  Step 37: reward=0.1161 loss=6.5239 kl=0.4360
  Step 38: reward=0.1186 loss=9.0939 kl=-0.4329
  Step 39: reward=0.1180 loss=8.9792 kl=0.3830
  Step 40: reward=0.1163 loss=1.0979 kl=0.2012
  Step 41: reward=0.1109 loss=31.2955 kl=0.0317
  Step 42: reward=0.1130 loss=0.5825 kl=-0.1997
  Step 43: reward=0.1228 loss=1.4495 kl=1.1522
  Step 44: reward=0.1224 loss=2.5196 kl=2.1674
  Step 45: reward=0.1192 loss=3.7601 kl=0.2163
  Step 46: reward=0.1148 loss=1.7214 kl=0.8720
  Step 47: reward=0.1193 loss=1.1424 kl=0.4176
  Step 48: reward=0.1207 loss=1.3946 kl=0.6416
  Step 49: reward=0.1185 loss=3.6421 kl=0.6550
  Step 50: reward=0.1170 loss=5.6597 kl=5.0473
  Eval reward=0.5782 toxicity=0.0781
Epoch 9/10
  Step 01: reward=0.1163 loss=3.7255 kl=1.5866
  Step 02: reward=0.1194 loss=2.0604 kl=1.7445
  Step 03: reward=0.1224 loss=14.7152 kl=-0.2034
  Step 04: reward=0.1202 loss=1.1108 kl=-0.0208
  Step 05: reward=0.1200 loss=0.9993 kl=-0.1050
  Step 06: reward=0.1225 loss=9.2691 kl=-0.0823
  Step 07: reward=0.1163 loss=1.2683 kl=0.8266
  Step 08: reward=0.1179 loss=4.1214 kl=1.4589
  Step 09: reward=0.1231 loss=27161.0117 kl=0.6841
  Step 10: reward=0.1214 loss=1.5884 kl=1.0516
  Step 11: reward=0.1209 loss=1.2410 kl=0.8511
  Step 12: reward=0.1251 loss=5.6715 kl=0.7011
  Step 13: reward=0.1193 loss=1.1991 kl=0.5196
  Step 14: reward=0.1186 loss=5.1959 kl=0.3847
  Step 15: reward=0.1164 loss=0.5989 kl=-0.0572
  Step 16: reward=0.1165 loss=2.3261 kl=-1.6364
  Step 17: reward=0.1181 loss=0.4042 kl=-0.0669
  Step 18: reward=0.1243 loss=1.2574 kl=0.5169
  Step 19: reward=0.1187 loss=0.5777 kl=-0.2763
  Step 20: reward=0.1096 loss=0.8000 kl=0.4074
  Step 21: reward=0.1185 loss=1.5986 kl=0.6717
  Step 22: reward=0.1231 loss=0.6422 kl=0.0298
  Step 23: reward=0.1246 loss=0.6013 kl=0.2080
  Step 24: reward=0.1109 loss=3.0934 kl=1.7206
  Step 25: reward=0.1226 loss=33538244083712.0000 kl=-0.9697
  Step 26: reward=0.1225 loss=0.7941 kl=0.4737
  Step 27: reward=0.1152 loss=0.7524 kl=-0.0592
  Step 28: reward=0.1216 loss=10.9506 kl=-3.1144
  Step 29: reward=0.1182 loss=2.3768 kl=1.6802
  Step 30: reward=0.1161 loss=37.9463 kl=0.0143
  Step 31: reward=0.1262 loss=0.9133 kl=0.4354
  Step 32: reward=0.1209 loss=0.9207 kl=0.6037
  Step 33: reward=0.1530 loss=3.5581 kl=-0.2888
  Step 34: reward=0.1209 loss=30.9201 kl=-0.2022
  Step 35: reward=0.1171 loss=58.1528 kl=-0.5494
  Step 36: reward=0.1202 loss=1.3338 kl=0.9190
  Step 37: reward=0.1167 loss=1.0202 kl=-0.6438
  Step 38: reward=0.1170 loss=3.1155 kl=-2.0902
  Step 39: reward=0.1239 loss=1.5085 kl=-0.6777
  Step 40: reward=0.1186 loss=7.3659 kl=0.0906
  Step 41: reward=0.1171 loss=6.8333 kl=0.9727
  Step 42: reward=0.1221 loss=1.9208 kl=-0.2557
  Step 43: reward=0.1238 loss=0.8624 kl=0.4801
  Step 44: reward=0.1186 loss=59449.8945 kl=-0.6100
  Step 45: reward=0.1590 loss=1.0365 kl=0.6452
  Step 46: reward=0.1163 loss=0.5735 kl=0.1810
  Step 47: reward=0.1148 loss=1.8718 kl=-0.6468
  Step 48: reward=0.1169 loss=3.0132 kl=-1.5771
  Step 49: reward=0.1157 loss=396.0652 kl=0.3473
  Step 50: reward=0.1240 loss=0.5171 kl=0.1584
  Eval reward=0.5763 toxicity=0.0809
Epoch 10/10
  Step 01: reward=0.1193 loss=1.0252 kl=0.5343
  Step 02: reward=0.1244 loss=5.5269 kl=0.4246
  Step 03: reward=0.1161 loss=3.4479 kl=2.6825
  Step 04: reward=0.1321 loss=1.1913 kl=0.8337
  Step 05: reward=0.1134 loss=132.2226 kl=-0.9344
  Step 06: reward=0.1206 loss=1644815843328.0000 kl=-1.7889
  Step 07: reward=0.1235 loss=0.8163 kl=0.0650
  Step 08: reward=0.1481 loss=11.3131 kl=-0.5333
  Step 09: reward=0.1183 loss=0.3903 kl=0.1432
  Step 10: reward=0.1123 loss=14109.0303 kl=-1.5953
  Step 11: reward=0.1134 loss=355.7117 kl=-1.6573
  Step 12: reward=0.1243 loss=3.6440 kl=-0.3842
  Step 13: reward=0.1236 loss=1.0439 kl=-0.2351
  Step 14: reward=0.1188 loss=16.4381 kl=-0.9089
  Step 15: reward=0.1116 loss=423984293694406656.0000 kl=-5.3998
  Step 16: reward=0.1172 loss=0.8803 kl=-0.2229
  Step 17: reward=0.1223 loss=3.1569 kl=0.4642
  Step 18: reward=0.1071 loss=374.9771 kl=-3.9064
  Step 19: reward=0.1291 loss=0.7963 kl=0.2835
  Step 20: reward=0.1162 loss=0.9515 kl=-0.3726
  Step 21: reward=0.1232 loss=2.0753 kl=-1.4902
  Step 22: reward=0.1200 loss=2.4629 kl=-0.2792
  Step 23: reward=0.1230 loss=2.5440 kl=0.8583
  Step 24: reward=0.1185 loss=1.6673 kl=1.0279
  Step 25: reward=0.1219 loss=0.6241 kl=-0.1759
  Step 26: reward=0.1190 loss=1.7429 kl=-0.2472
  Step 27: reward=0.1158 loss=2.4063 kl=0.9099
  Step 28: reward=0.1148 loss=1.9263 kl=-0.0201
  Step 29: reward=0.1195 loss=2.9582 kl=1.1339
  Step 30: reward=0.1153 loss=1.3995 kl=0.2437
  Step 31: reward=0.1194 loss=0.7241 kl=0.2395
  Step 32: reward=0.1225 loss=0.9485 kl=0.5247
  Step 33: reward=0.1138 loss=0.8047 kl=0.4668
  Step 34: reward=0.1185 loss=1.9363 kl=0.1542
  Step 35: reward=0.1239 loss=0.9018 kl=0.1910
  Step 36: reward=0.1240 loss=1.8292 kl=0.6720
  Step 37: reward=0.1230 loss=0.9504 kl=0.2978
  Step 38: reward=0.1168 loss=1.1929 kl=0.7374
  Step 39: reward=0.1099 loss=1.3843 kl=0.9835
  Step 40: reward=0.1226 loss=2.4613 kl=0.2522
  Step 41: reward=0.1172 loss=3.5264 kl=0.2377
  Step 42: reward=0.1193 loss=1.6044 kl=-0.0367
  Step 43: reward=0.1207 loss=2.3776 kl=-1.9964
  Step 44: reward=0.1189 loss=1.6927 kl=-0.9480
  Step 45: reward=0.1351 loss=2.5243 kl=-0.1713
  Step 46: reward=0.1222 loss=3.7898 kl=-2.6800
  Step 47: reward=0.1208 loss=0.8221 kl=0.2664
  Step 48: reward=0.1113 loss=1.4598 kl=0.8337
  Step 49: reward=0.1148 loss=1.4626 kl=1.0245
  Step 50: reward=0.1235 loss=42.0036 kl=0.3157
  Eval reward=0.5786 toxicity=0.0782
RLHF PPO policy saved to RL/full_run_jonly/blenderbot/ppo_policy
RLHF model saved to RL/full_run_jonly/blenderbot/final_model
Running inference over held-out set...
Generating test predictions:   0%|          | 0/62 [00:00<?, ?it/s]Generating test predictions:   2%|▏         | 1/62 [00:04<04:16,  4.20s/it]Generating test predictions:   3%|▎         | 2/62 [00:06<03:18,  3.32s/it]Generating test predictions:   5%|▍         | 3/62 [00:10<03:16,  3.34s/it]Generating test predictions:   6%|▋         | 4/62 [00:13<03:06,  3.22s/it]Generating test predictions:   8%|▊         | 5/62 [00:15<02:48,  2.95s/it]Generating test predictions:  10%|▉         | 6/62 [00:18<02:39,  2.85s/it]Generating test predictions:  11%|█▏        | 7/62 [00:21<02:45,  3.01s/it]Generating test predictions:  13%|█▎        | 8/62 [00:25<02:47,  3.10s/it]Generating test predictions:  15%|█▍        | 9/62 [00:28<02:42,  3.07s/it]Generating test predictions:  16%|█▌        | 10/62 [00:32<03:06,  3.58s/it]Generating test predictions:  18%|█▊        | 11/62 [00:36<03:00,  3.54s/it]Generating test predictions:  19%|█▉        | 12/62 [00:39<02:49,  3.39s/it]Generating test predictions:  21%|██        | 13/62 [00:42<02:41,  3.29s/it]Generating test predictions:  23%|██▎       | 14/62 [00:45<02:35,  3.23s/it]Generating test predictions:  24%|██▍       | 15/62 [00:47<02:21,  3.00s/it]Generating test predictions:  26%|██▌       | 16/62 [00:51<02:23,  3.12s/it]Generating test predictions:  27%|██▋       | 17/62 [00:54<02:18,  3.08s/it]Generating test predictions:  29%|██▉       | 18/62 [00:56<02:10,  2.96s/it]Generating test predictions:  31%|███       | 19/62 [00:59<02:01,  2.83s/it]Generating test predictions:  32%|███▏      | 20/62 [01:02<01:56,  2.77s/it]Generating test predictions:  34%|███▍      | 21/62 [01:04<01:51,  2.72s/it]Generating test predictions:  35%|███▌      | 22/62 [01:08<01:56,  2.92s/it]Generating test predictions:  37%|███▋      | 23/62 [01:14<02:29,  3.84s/it]Generating test predictions:  39%|███▊      | 24/62 [01:16<02:13,  3.51s/it]Generating test predictions:  40%|████      | 25/62 [01:20<02:12,  3.57s/it]Generating test predictions:  42%|████▏     | 26/62 [01:23<02:02,  3.41s/it]Generating test predictions:  44%|████▎     | 27/62 [01:26<01:53,  3.24s/it]Generating test predictions:  45%|████▌     | 28/62 [01:30<02:02,  3.59s/it]Generating test predictions:  47%|████▋     | 29/62 [01:33<01:52,  3.42s/it]Generating test predictions:  48%|████▊     | 30/62 [01:36<01:45,  3.31s/it]Generating test predictions:  50%|█████     | 31/62 [01:39<01:40,  3.23s/it]Generating test predictions:  52%|█████▏    | 32/62 [01:45<01:55,  3.86s/it]Generating test predictions:  53%|█████▎    | 33/62 [01:48<01:44,  3.62s/it]Generating test predictions:  55%|█████▍    | 34/62 [01:51<01:35,  3.41s/it]Generating test predictions:  56%|█████▋    | 35/62 [01:54<01:32,  3.44s/it]Generating test predictions:  58%|█████▊    | 36/62 [01:57<01:24,  3.24s/it]Generating test predictions:  60%|█████▉    | 37/62 [02:00<01:18,  3.16s/it]Generating test predictions:  61%|██████▏   | 38/62 [02:03<01:15,  3.13s/it]Generating test predictions:  63%|██████▎   | 39/62 [02:07<01:18,  3.39s/it]Generating test predictions:  65%|██████▍   | 40/62 [02:10<01:13,  3.34s/it]Generating test predictions:  66%|██████▌   | 41/62 [02:13<01:06,  3.18s/it]Generating test predictions:  68%|██████▊   | 42/62 [02:16<01:03,  3.19s/it]Generating test predictions:  69%|██████▉   | 43/62 [02:19<00:59,  3.14s/it]Generating test predictions:  71%|███████   | 44/62 [02:23<00:59,  3.32s/it]Generating test predictions:  73%|███████▎  | 45/62 [02:26<00:54,  3.22s/it]Generating test predictions:  74%|███████▍  | 46/62 [02:29<00:49,  3.07s/it]Generating test predictions:  76%|███████▌  | 47/62 [02:31<00:43,  2.92s/it]Generating test predictions:  77%|███████▋  | 48/62 [02:34<00:40,  2.93s/it]Generating test predictions:  79%|███████▉  | 49/62 [02:37<00:37,  2.87s/it]Generating test predictions:  81%|████████  | 50/62 [02:40<00:33,  2.81s/it]Generating test predictions:  82%|████████▏ | 51/62 [02:43<00:32,  2.95s/it]Generating test predictions:  84%|████████▍ | 52/62 [02:47<00:32,  3.27s/it]Generating test predictions:  85%|████████▌ | 53/62 [02:50<00:28,  3.20s/it]Generating test predictions:  87%|████████▋ | 54/62 [02:54<00:26,  3.31s/it]Generating test predictions:  89%|████████▊ | 55/62 [02:58<00:25,  3.63s/it]Generating test predictions:  90%|█████████ | 56/62 [03:01<00:20,  3.43s/it]Generating test predictions:  92%|█████████▏| 57/62 [03:05<00:17,  3.52s/it]Generating test predictions:  94%|█████████▎| 58/62 [03:08<00:13,  3.49s/it]Generating test predictions:  95%|█████████▌| 59/62 [03:11<00:10,  3.34s/it]Generating test predictions:  97%|█████████▋| 60/62 [03:14<00:06,  3.34s/it]Generating test predictions:  98%|█████████▊| 61/62 [03:18<00:03,  3.33s/it]Generating test predictions: 100%|██████████| 62/62 [03:21<00:00,  3.28s/it]                                                                            Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Saved predictions to RL/full_run_jonly/blenderbot/test_results.tsv
Computing ParaDetox metrics...
Loaded 1973 examples with model outputs.
Using device: cpu

Computing BLEU...
Computing Style Accuracy (STA)...
Computing Content Preservation (SIM)...
Batches:   0%|          | 0/31 [00:00<?, ?it/s]Batches:   3%|▎         | 1/31 [00:00<00:26,  1.11it/s]Batches:   6%|▋         | 2/31 [00:01<00:13,  2.12it/s]Batches:  10%|▉         | 3/31 [00:01<00:08,  3.31it/s]Batches:  13%|█▎        | 4/31 [00:01<00:06,  4.30it/s]Batches:  16%|█▌        | 5/31 [00:01<00:05,  4.76it/s]Batches:  19%|█▉        | 6/31 [00:01<00:04,  5.75it/s]Batches:  26%|██▌       | 8/31 [00:01<00:02,  8.47it/s]Batches:  32%|███▏      | 10/31 [00:01<00:02,  9.72it/s]Batches:  39%|███▊      | 12/31 [00:02<00:01, 10.62it/s]Batches:  45%|████▌     | 14/31 [00:02<00:01, 11.57it/s]Batches:  52%|█████▏    | 16/31 [00:02<00:01, 12.25it/s]Batches:  58%|█████▊    | 18/31 [00:02<00:01, 12.10it/s]Batches:  65%|██████▍   | 20/31 [00:02<00:00, 12.77it/s]Batches:  74%|███████▍  | 23/31 [00:02<00:00, 11.15it/s]Batches:  81%|████████  | 25/31 [00:03<00:00, 12.30it/s]Batches:  87%|████████▋ | 27/31 [00:03<00:00, 12.72it/s]Batches:  97%|█████████▋| 30/31 [00:03<00:00, 14.87it/s]Batches: 100%|██████████| 31/31 [00:03<00:00,  9.06it/s]
Batches:   0%|          | 0/31 [00:00<?, ?it/s]Batches:   3%|▎         | 1/31 [00:00<00:07,  3.84it/s]Batches:   6%|▋         | 2/31 [00:00<00:07,  3.79it/s]Batches:  10%|▉         | 3/31 [00:00<00:05,  5.12it/s]Batches:  16%|█▌        | 5/31 [00:00<00:03,  7.57it/s]Batches:  23%|██▎       | 7/31 [00:00<00:02,  9.17it/s]Batches:  29%|██▉       | 9/31 [00:01<00:02, 10.34it/s]Batches:  35%|███▌      | 11/31 [00:01<00:01, 11.39it/s]Batches:  42%|████▏     | 13/31 [00:01<00:01, 11.91it/s]Batches:  48%|████▊     | 15/31 [00:01<00:01, 12.42it/s]Batches:  55%|█████▍    | 17/31 [00:01<00:01, 11.98it/s]Batches:  61%|██████▏   | 19/31 [00:01<00:00, 12.71it/s]Batches:  68%|██████▊   | 21/31 [00:02<00:00, 13.28it/s]Batches:  74%|███████▍  | 23/31 [00:02<00:00, 13.72it/s]Batches:  81%|████████  | 25/31 [00:02<00:00, 14.18it/s]Batches:  87%|████████▋ | 27/31 [00:02<00:00, 14.48it/s]Batches:  94%|█████████▎| 29/31 [00:02<00:00, 14.34it/s]Batches: 100%|██████████| 31/31 [00:02<00:00, 13.97it/s]Batches: 100%|██████████| 31/31 [00:02<00:00, 11.44it/s]
Computing Fluency (FL)...

=== ParaDetox-style Metrics ===
BLEU:   8.79
STA :  0.959
SIM :  0.711
FL  :  0.713
J   :  0.486
Metrics written to RL/full_run_jonly/blenderbot/metrics.txt
