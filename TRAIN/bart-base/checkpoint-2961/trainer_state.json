{
  "best_global_step": 2961,
  "best_metric": 0.8978590965270996,
  "best_model_checkpoint": "./TRAIN/detox_model_output/checkpoint-2961",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2961,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10131712259371833,
      "grad_norm": 9.968254089355469,
      "learning_rate": 5.940000000000001e-06,
      "loss": 2.131,
      "step": 100
    },
    {
      "epoch": 0.20263424518743667,
      "grad_norm": 7.668097019195557,
      "learning_rate": 1.1940000000000001e-05,
      "loss": 1.4095,
      "step": 200
    },
    {
      "epoch": 0.303951367781155,
      "grad_norm": 9.74873161315918,
      "learning_rate": 1.794e-05,
      "loss": 1.2599,
      "step": 300
    },
    {
      "epoch": 0.40526849037487334,
      "grad_norm": 5.3819684982299805,
      "learning_rate": 2.394e-05,
      "loss": 1.1932,
      "step": 400
    },
    {
      "epoch": 0.5065856129685917,
      "grad_norm": 11.380627632141113,
      "learning_rate": 2.994e-05,
      "loss": 1.1126,
      "step": 500
    },
    {
      "epoch": 0.60790273556231,
      "grad_norm": 5.085539817810059,
      "learning_rate": 2.9330326944757612e-05,
      "loss": 1.1338,
      "step": 600
    },
    {
      "epoch": 0.7092198581560284,
      "grad_norm": 4.673468112945557,
      "learning_rate": 2.8653889515219845e-05,
      "loss": 1.0819,
      "step": 700
    },
    {
      "epoch": 0.8105369807497467,
      "grad_norm": 4.9171977043151855,
      "learning_rate": 2.7977452085682075e-05,
      "loss": 1.092,
      "step": 800
    },
    {
      "epoch": 0.9118541033434651,
      "grad_norm": 4.208287715911865,
      "learning_rate": 2.7301014656144308e-05,
      "loss": 1.0391,
      "step": 900
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9168425798416138,
      "eval_runtime": 23.2554,
      "eval_samples_per_second": 84.798,
      "eval_steps_per_second": 5.332,
      "step": 987
    },
    {
      "epoch": 1.0131712259371835,
      "grad_norm": 4.735069274902344,
      "learning_rate": 2.6624577226606538e-05,
      "loss": 1.0332,
      "step": 1000
    },
    {
      "epoch": 1.1144883485309016,
      "grad_norm": 4.638589859008789,
      "learning_rate": 2.594813979706877e-05,
      "loss": 0.927,
      "step": 1100
    },
    {
      "epoch": 1.21580547112462,
      "grad_norm": 5.20768928527832,
      "learning_rate": 2.5271702367531004e-05,
      "loss": 0.9768,
      "step": 1200
    },
    {
      "epoch": 1.3171225937183384,
      "grad_norm": 4.8552937507629395,
      "learning_rate": 2.4595264937993237e-05,
      "loss": 0.9189,
      "step": 1300
    },
    {
      "epoch": 1.4184397163120568,
      "grad_norm": 5.291012287139893,
      "learning_rate": 2.391882750845547e-05,
      "loss": 0.8962,
      "step": 1400
    },
    {
      "epoch": 1.5197568389057752,
      "grad_norm": 5.7260637283325195,
      "learning_rate": 2.32423900789177e-05,
      "loss": 0.9025,
      "step": 1500
    },
    {
      "epoch": 1.6210739614994933,
      "grad_norm": 5.068533897399902,
      "learning_rate": 2.2565952649379932e-05,
      "loss": 0.9372,
      "step": 1600
    },
    {
      "epoch": 1.7223910840932117,
      "grad_norm": 4.545814037322998,
      "learning_rate": 2.1889515219842166e-05,
      "loss": 0.911,
      "step": 1700
    },
    {
      "epoch": 1.8237082066869301,
      "grad_norm": 4.84944486618042,
      "learning_rate": 2.12130777903044e-05,
      "loss": 0.902,
      "step": 1800
    },
    {
      "epoch": 1.9250253292806483,
      "grad_norm": 3.885044574737549,
      "learning_rate": 2.0536640360766628e-05,
      "loss": 0.9094,
      "step": 1900
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.910663366317749,
      "eval_runtime": 24.1752,
      "eval_samples_per_second": 81.571,
      "eval_steps_per_second": 5.129,
      "step": 1974
    },
    {
      "epoch": 2.026342451874367,
      "grad_norm": 5.8522844314575195,
      "learning_rate": 1.986020293122886e-05,
      "loss": 0.8678,
      "step": 2000
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 5.331557750701904,
      "learning_rate": 1.9183765501691094e-05,
      "loss": 0.8221,
      "step": 2100
    },
    {
      "epoch": 2.2289766970618032,
      "grad_norm": 4.831579685211182,
      "learning_rate": 1.8507328072153327e-05,
      "loss": 0.7931,
      "step": 2200
    },
    {
      "epoch": 2.330293819655522,
      "grad_norm": 4.466322898864746,
      "learning_rate": 1.7830890642615557e-05,
      "loss": 0.8103,
      "step": 2300
    },
    {
      "epoch": 2.43161094224924,
      "grad_norm": 4.7545928955078125,
      "learning_rate": 1.715445321307779e-05,
      "loss": 0.7899,
      "step": 2400
    },
    {
      "epoch": 2.5329280648429586,
      "grad_norm": 6.0243239402771,
      "learning_rate": 1.6478015783540023e-05,
      "loss": 0.8002,
      "step": 2500
    },
    {
      "epoch": 2.634245187436677,
      "grad_norm": 3.587139368057251,
      "learning_rate": 1.5801578354002256e-05,
      "loss": 0.8033,
      "step": 2600
    },
    {
      "epoch": 2.735562310030395,
      "grad_norm": 4.517576217651367,
      "learning_rate": 1.5125140924464488e-05,
      "loss": 0.7823,
      "step": 2700
    },
    {
      "epoch": 2.8368794326241136,
      "grad_norm": 4.934699535369873,
      "learning_rate": 1.4448703494926719e-05,
      "loss": 0.7834,
      "step": 2800
    },
    {
      "epoch": 2.9381965552178317,
      "grad_norm": 11.682910919189453,
      "learning_rate": 1.3772266065388952e-05,
      "loss": 0.7748,
      "step": 2900
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8978590965270996,
      "eval_runtime": 27.1926,
      "eval_samples_per_second": 72.52,
      "eval_steps_per_second": 4.56,
      "step": 2961
    }
  ],
  "logging_steps": 100,
  "max_steps": 4935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 663555227811840.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
